{
    "contents" : "# Iris data\n\ndata(iris)\niris2 <- iris\nlevels(iris2$Species) <- c('s','e','v')\n# otherwise v*e*rsicolor are mixed ip with *v*irginica\n\n\n## Exploramos los datos inicialmente\n\n\nplot(iris[,1:4], col=as.numeric(iris$Species))\n\n## Estimaci�n de la densidad condicional (estimadores kernel)\n\nlibrary(lattice)\ndensityplot( ~ Petal.Width+Petal.Length+Sepal.Length+Sepal.Width, groups=Species, data=iris2)\n\n\n\n## Analisis Discriminante Lineal (lda).\n## Estimaci�n de la matriz de mala clasificaci�n y del error de mala clasificacion aparente (peligro de optimismo)\nrequire(MASS)\nmod.lda <- lda(Species ~ ., data = iris2)\nmod.lda\n\n## representacion de las dos grupos de acuerdo con las dos primeras variables can�nica de clasificaci�n\n\n\nplot(mod.lda)\n\n\n## Estimaci�n de la matriz de mala clasificaci�n y del error de mala clasificacion aparente (peligro de optimismo)\n\npredictLDA <- predict(mod.lda)\nTAB <- table(iris2$Species, predictLDA$class)\nTAB\n# observando la tabla, vemos que de la clase s se clasifican 50 bien, de e sólo 48 y de v 49 y 2 y 1 confusiones\nmcrlda <- 1 - sum(diag(TAB))/sum(TAB) # proporcion de fallos, sumando la diagonal entre el total y haciendo el complementario\nmcrlda # un 2% de mal clasificados\n\n## Representamos  de forma simultanea la frontera y los datos (utilizamos las variables can�nicas de discriminacion) \n## Uso de la funci�n partimat de la libreria klaR\n\nlibrary(klaR)\n\niris3<-cbind(iris2, predictLDA$x[,1:2]) # añadimos el iris2 a las que acabamos de obtener\n\npartimat(Species ~ LD2+LD1, data=iris3, method=\"lda\")\n\npartimat(Species ~., data=iris2, method=\"lda\", plot.matrix=TRUE)\n\n\n## Uso de la libreria ggplot y representacion simultanea de datos y contornos de densidad (estimaci�n kernel)\n\nlibrary(ggplot2)\n\nquickplot(iris3$LD1,iris3$LD2, colour=iris3$Species, geom=c(\"point\",\"density2d\"))\n\n\n\n## Analisis Discriminante Cuadr�tico (qda).\n## Estimaci�n de la matriz de mala clasificaci�n y del error de mala clasificacion aparente (peligro de optimismo)\n\nmod.qda <- qda(Species ~ ., data = iris2)\nmod.qda\n\n## Estimaci�n de la matriz de mala clasificaci�n y del error de mala clasificacion aparente (peligro de optimismo)\n\npredictQDA <- predict(mod.qda)\nTAB <- table(iris2$Species, predictQDA$class)\nTAB\nmcrqda <- 1 - sum(diag(TAB))/sum(TAB)\nmcrqda\n\n## Representamos  de forma simultanea la frontera y los datos (utilizamos las variables can�nicas de discriminacion) \n## Uso de la funci�n partimat de la libreria klaR\n\nlibrary(klaR)\n\n\n\npartimat(Species ~ ., data=iris2, method=\"qda\", plot.matrix=TRUE)\n\n\n## Naive Bayes (e1071). En v. métricas asume normalidad. Admite suavizado de laplace.\nlibrary(e1071)\nmod.NB <- naiveBayes(Species ~ ., data = iris2)\nmod.NB\n\n## Estimaci�n de la matriz de mala clasificaci�n y del error de mala clasificacion aparente (peligro de optimismo)\n\npredictNB <- predict(mod.NB, newdata=iris2)\nTAB <- table(iris2$Species, predictNB)\nTAB\nmcrNB <- 1 - sum(diag(TAB))/sum(TAB)\nmcrNB\n\npartimat(Species ~., data=iris2, method=\"naiveBayes\", plot.matrix=TRUE)\n\n\n\n## EStimacion por knn  (k=3 default) http://es.wikipedia.org/wiki/Knn\n# construye un clasificador basandose en los3 vecinos próximos\n\nmod.sknn <- sknn(Species ~ ., data = iris2, gamma=0)\nmod.sknn\n\n## Estimaci�n de la matriz de mala clasificaci�n y del error de mala clasificacion aparente (peligro de optimismo)\n\n\npredictsknn <- predict(mod.sknn, newdata=iris2)\nTAB <- table(iris2$Species, predictsknn$class)\nTAB\nmcrsknn <- 1 - sum(diag(TAB))/sum(TAB)\nmcrsknn\n# gamma es el suavizado, gamma = 0.0 no suaviza\npartimat(Species ~., data=iris2, method=\"sknn\", plot.matrix=TRUE, gamma=0.0)\n\n\n\n\n## Seleccion de la variables\n\n## Uso de la fucion stepclass de klaR. improvement=0.001 o m�s peque�o para que entren 2 o m�s variables\n## Uso del error aparente.\n# permite hacer una selección secuencial de las variables más relevantes  \n\n# Lineal\n\nstepclass(Species~., data=iris2, method=\"lda\", improvement=0.001)\n\n# Cuadr�tico\n\nstepclass(Species~., data=iris2, method=\"qda\", improvement=0.001)\n\n\n\n### Seleccion de parámetros por \"fuerza bruta\" (grid search). \n### Funcion tune () (e1071)\n\n## tune `knn' using a convenience function; this time with the\n## conventional interface and bootstrap sampling:\nx <- iris2[,-5]\ny <- iris2[,5]\n\n# Función tune para knn\n# de 1 a 15 vecinos próximos, x matriz de datos, y variable categorica especies\n# remuestreamos de un conjunto de individuos, en los que puede haber repeticiones\n# utilizando la filosofia bootstrap, más de 100\n\nobj2 <- tune.knn(x,y, k = 1:15, tunecontrol = tune.control(sampling = \"boot\",nboot=900))\nsummary(obj2)\nplot(obj2)\n\ntune.knn(x,y, k = 12, tunecontrol = tune.control(sampling = \"boot\",nboot=500))\nsummary(obj2)\nplot(obj2)\n\n\n\n## funcion para resumir la capacidad clasificatoria de un m�todo\n## admite prob. a priori\n\nconfusion <- function(actual, predicted, names=NULL, \n                      printit=TRUE, prior=NULL){\n  if(is.null(names))names <- levels(actual)\n  tab <- table(actual, predicted)\n  acctab <- t(apply(tab, 1, function(x)x/sum(x)))\n  dimnames(acctab) <- list(Actual=names,\n                           \"Predicted (cv)\"=names) \n  if(is.null(prior)){\n    relnum <- table(actual)\n    prior <- relnum/sum(relnum)\n    acc <- sum(tab[row(tab)==col(tab)])/sum(tab)\n  } else\n  {\n    acc <- sum(prior*diag(acctab))\n    names(prior) <- names\n  }    \n  if(printit)print(round(c(\"Overall accuracy\"=acc, \n                           \"Prior frequency\"=prior),4))\n  if(printit){    cat(\"\\nConfusion matrix\", \"\\n\")\n                  print(round(acctab,4))\n  }\n  invisible(acctab)\n}\n\n\n## Ejemplo con los datos iris\n\nconfusion(iris2$Species, predictLDA$class)\n\n## Primer intento de obtener una estimaci�n con menor optimismo\n## uso de CV=TRUE\n\n\n# Lineal\n\nconfusion(iris2$Species, lda(Species ~., data=iris2,CV=TRUE)$class)\n\n# Cuadratico\n\n\nconfusion(iris2$Species, qda(Species ~., data=iris2,CV=TRUE)$class)\n\ntable(iris2$Species, qda(Species ~., data=iris2,CV=TRUE)$class)\n\n\n\n\n\n\n###################################\n# Tarea: Repetir el an�lisis con los datos crabs de la libreria(MASS)\n####################################\n\n\n#lectura y creacion de 4 grupos\n\nlibrary(MASS)\ndata(crabs)\nspsex <- 2 * as.numeric(crabs$sp) + as.numeric(crabs$sex)\nspsex<-factor(spsex, levels=c(3,4,5,6), labels=c(\"b\",\"B\",\"o\",\"O\"))\n\nplot(crabs[, 4:8], col = spsex)\n\ndensityplot( ~ FL+RW+CL+CW+BD, groups=spsex, data=crabs)\n\n\n# ampliamos el conjunto de datos con las 3 primeras componentes principales\n\ncrabsPC <- predict(princomp(crabs[, 4:8]))\npairs(crabsPC[, 1:3], col = spsex)\ncrabs2<-cbind(crabs,spsex, crabsPC[,1:3])\nnames(crabs2)\n\nmod.lda <- lda(spsex ~ Comp.1+Comp.2+Comp.3, data = crabs2)\nmod.lda\n\n\n# continuar .....\n\n\n\n\n## Datos de los indios Pima\n## Existe un grupo de entrenamiento y otro de validacion\n## 2 grupos, numerosas variables (discretas y continuas)\n\nlibrary(MASS)\n\ndata(Pima.tr)\nhelp(Pima.tr)\n\n\n\nplot(Pima.tr[,1:7],col=Pima.tr[,8])\n\n\ndensityplot( ~ Pima.tr[,1:7], groups=Pima.tr$type, data=Pima.tr)\n\nmod.lda <- lda(type ~ ., data = Pima.tr)\npredictLDA <- predict(mod.lda, newdata = Pima.te)\nTAB <- table(Pima.te$type, predictLDA$class)\nTAB\nmcrlda <- 1 - sum(diag(TAB))/sum(TAB)\nmcrlda\n\nconfusion(Pima.te$type, predictLDA$class)\n\n\n\nmod.qda <- qda(type ~ ., data = Pima.tr)\npredictQDA <- predict(mod.qda, newdata = Pima.te)\nTAB <- table(Pima.te$type, predictQDA$class)\nTAB\nmcrqda <- 1 - sum(diag(TAB))/sum(TAB)\nmcrqda\n\n\nconfusion(Pima.te$type, predictQDA$class)\n\n\n### MODELO de REGRESION LOG�STICA\n\npima.glm1<-glm(type~., binomial, data=Pima.tr) # para los Pima.training\nsummary(pima.glm1)\n\npredictGLM<-predict(pima.glm1, newdata= Pima.te, type = \"response\") # para los Pima.test\n\nTAB <- table(Pima.te$type, predictGLM > .5) # modificacion: nos quedamos con los valores predichos > 0.5\nTAB\nmcrglm1 <- 1 - sum(diag(TAB))/sum(TAB)\nmcrglm1\n\n\n# alternativamente\n\nTAB <- table(Pima.te$type, round(predictGLM )) # similar a > .5 en este caso, lo que hace es redondear a 0 o a 1\nTAB\nmcrglm1 <- 1 - sum(diag(TAB))/sum(TAB)\nmcrglm1\n\n\n\nconfusion(Pima.te$type, (predictGLM > .5))\n\n\n\n## visualizacion de los efectos\n\ntermplot(pima.glm1, se=TRUE, rug=TRUE)\n\n# Alternativa library(effecst)\n\nrequire(effects)\nplot(allEffects(pima.glm1))\n\n# vemos que por ejemplo en la edad tenemos una gran banda de icertidumbre aunque tiene mucha relevancia en la diabetes\n# sin embargo el valor bp no influye, es una línea plana, o skin también\n\n## a�adir suavizadores para detectar efecto no lineal\n\ntermplot(pima.glm1, partial.resid=TRUE, se=TRUE, rug=TRUE, smooth=panel.smooth, span.smth=1/5)\n\n## Suele ser necesario un n�mero grande de casos para\n## poder visualizar un efecto no lineal de forma clara.\n\n\nstepAIC(pima.glm1)\n\npima.glm2<-step(pima.glm1)\n\nsummary(pima.glm2)\n\n## Ajustamos un modelo con posibles interacciones de orden 2.\n\nstepAIC(pima.glm1, scope=c(upper=.~.^2, lower=.~1))\n\npima.glm3<-stepAIC(pima.glm1, scope=c(upper=.~.^2, lower=.~1)) # interacciones de ornde 2 entre lsa variables\n\nsummary(pima.glm3)\n\nconfusion(Pima.te$type ,round(predict(pima.glm3, newdata= Pima.te, type = \"response\")))\n\n# visualización de interacciones\n\nplot(allEffects(pima.glm3))\n\n#notar la diferencia con \n\nstepAIC(glm(type~.^2,binomial, data=Pima.tr))\n\n\n\n\n\n# evaluamos la capacidad predictiva del modelo \n# utilizamos una funci�n de la libreria boot\n\nlibrary(boot)\n# esta funci�n cuenta la proporci�n de errores de predicci�n\n\ncost <- function(r, pi=0) mean(abs(r-pi)>0.5)\n\n# error de predicci�n con cross-validation K-fold\ncv.glm(Pima.tr, pima.glm2, cost, K=50)\n\n\n# si queremos un metodo de estimacion de tipo leave-one-out\n# omitimos el valor de K (se puede hacer algo lento)\n\ncv.glm(Pima.tr, pima.glm2, cost)\n\n# en ambos casos, los errores estimados son mayores que\n# el error aparente\n\nfitpima.glm2<-predict(pima.glm2, type=\"response\") \ntable(Pima.tr$type,fitpima.glm2 > 0.5)\n\n\n\n\n\n\n## ROC curve para lda y Pima\n\ntruepos <- numeric(19)\nfalsepos <- numeric(19)\np1 <- (1:19)/20\nfor(i in 1:19){\n  p <- p1[i]\n  Pima.CV1p <- lda(type ~ ., data=Pima.tr, CV=TRUE, prior=c(p, 1-p))\n  confmat <- confusion(Pima.tr$type, Pima.CV1p$class, printit=FALSE)\n  falsepos[i] <- confmat[1,2]\n  truepos[i] <- confmat[2,2]\n}\n\nplot(truepos ~ falsepos, type=\"l\", xlab=\"False positive rate\",\n     ylab=\"True positive rate (Sensitivity)\")\n\n\nfor(i in 1:19){\n  p <- p1[i]\n  Pima.CV1p <- qda(type ~ ., data=Pima.tr, CV=TRUE, prior=c(p, 1-p))\n  confmat <- confusion(Pima.tr$type, Pima.CV1p$class, printit=FALSE)\n  falsepos[i] <- confmat[1,2]\n  truepos[i] <- confmat[2,2]\n}\n\n\nlines(truepos ~ falsepos, type=\"l\", col=2)\n\n#ARBoles\n\n\n\nlibrary(rpart)\nmodeltree<-rpart(  type~. ,data=Pima.tr, method=\"class\")\nsummary(modeltree)\n\nplot(modeltree)\ntext(modeltree)\nplotcp(modeltree)\n\nmod.TREE<-rpart(type~. ,data=Pima.tr, cp=0.025)\n\n# o bien\n##  mod.TREE<-prune(modeltree, cp=0.025)\n\nrpart(  type~. ,data=Pima.tr, method=\"class\", parms=list( split='information'))\n\n\n\npredictTREE <- predict(mod.TREE, newdata = Pima.te, type=\"class\")\nTAB <- table(Pima.te$type, predictTREE)\nmcrtree <- 1 - sum(diag(TAB))/sum(TAB)\nmcrtree\n\n\n\n### Random Forest\n\nlibrary(randomForest)\n\nPima.rf <- randomForest(type~., data=Pima.tr, xtest=Pima.te[,-8],\n                        ytest=Pima.te$type)\nPima.rf\n\nplot(Pima.rf)\n\n## ejermplo de uso de la libreria RWeka para una clasificacion\n\n\nlibrary(RWeka)\n\nmod.J48 <- J48(type ~ ., data = Pima.tr)\n## print and summary\nmod.J48\nsummary(mod.J48) # calls evaluate_Weka_classifier()\nTAB <- table(Pima.te$type, predict(mod.J48, type=\"class\", newdata=Pima.te))\nmcrJ48 <- 1 - sum(diag(TAB))/sum(TAB)\nmcrJ48\n",
    "created" : 1424634986235.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1974164303",
    "id" : "43F0DFB6",
    "lastKnownWriteTime" : 1423832006,
    "path" : "~/Master/mineria/p2/md130215.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}